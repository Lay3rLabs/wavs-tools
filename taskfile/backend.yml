version: "3"

includes:
  config:
    taskfile: ./config.yml
    flatten: true
  docker:
    taskfile: ./docker.yml
    flatten: true

env:
  # avoid namespace conflicts with other env vars
  # see https://github.com/go-task/task/issues/1038
  COMPOSE_FOUNDRY_DOCKER_IMAGE: "{{.FOUNDRY_DOCKER_IMAGE}}"
  COMPOSE_WAVS_DOCKER_IMAGE: "{{.WAVS_DOCKER_IMAGE}}"
  COMPOSE_JAEGER_DOCKER_IMAGE: "{{.JAEGER_DOCKER_IMAGE}}"
  COMPOSE_PROMETHEUS_DOCKER_IMAGE: "{{.PROMETHEUS_DOCKER_IMAGE}}"
  COMPOSE_WAVS_HOME: "{{.WAVS_HOME_DIR}}"

tasks:
  start:
    desc: "Starts all backend services"
    deps:
      - task: start-chains
        vars:
          CHAINS: "{{.CHAINS}}"
      - task: start-wavs
        vars:
          OPERATORS: "{{.OPERATORS}}"
      - task: start-telemetry
    cmds:
      - task: configure-chains

  stop:
    desc: "Stops all backend services"
    deps:
      - task: stop-chains
      - task: stop-wavs
      - task: stop-telemetry

  ###################################################################
  ######################## Chains ###################################
  ###################################################################
  start-chains:
    desc: "Start Anvil blockchain instances for local development"
    status:
      - '[ "{{.DEPLOY_ENV}}" != "LOCAL" ]'
    preconditions:
      - test -f "{{.BACKEND_DIR}}/docker-compose-anvil.yml"
      - sh: "command -v docker"
        msg: "Docker is required but not installed"
    # Pull the latest images before starting
    deps: [docker-pull-chains]
    cmds:
      - task: start-chains-inner
        # Optional - pass this in
        vars:
          CHAINS: "{{.CHAINS | default 1}}"

  start-chains-inner:
    internal: true
    vars:
      CHAIN_RANGE:
        sh: seq 1 {{.CHAINS}}
    requires:
      vars: [CHAINS]
    deps:
      # All of these are started in parallel
      - for: { var: CHAIN_RANGE }
        task: start-chain-{{.ITEM}}

  stop-chains:
    desc: "Stop all running Anvil blockchain instances"
    vars:
      ACTIVE_CHAINS:
        sh: seq 1 {{.ACTIVE_CHAIN_COUNT}}
    deps:
      - for: { var: ACTIVE_CHAINS }
        task: stop-chain-{{.ITEM}}

  stop-chain-*:
    internal: true
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
    cmds:
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --project-name anvil-{{.CHAIN_NUMBER}} --file docker-compose-anvil.yml down --remove-orphans --volumes

  start-chain-*:
    internal: true
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
      ANVIL_PORT:
        sh: task backend:get-anvil-port-{{.CHAIN_NUMBER}}
    deps:
      - task: docker-start-chain-{{index .MATCH 0}}
    cmds:
      # Wait for the Anvil chain to be up and running
      # The deps here will ensure that the docker-start-chain-* task is run first
      - |
        for ((i=0; i<{{.HEALTH_CHECK_TIMEOUT}}; i++)); do
          if nc -z 127.0.0.1 {{.ANVIL_PORT}}; then
            break
          fi
          echo "Waiting for Anvil chain #{{.CHAIN_NUMBER}} to start on port {{.ANVIL_PORT}}..."
          sleep 1
        done
        if ! nc -z 127.0.0.1 {{.ANVIL_PORT}}; then
          echo "Anvil did not start after {{.HEALTH_CHECK_TIMEOUT}} seconds"
          exit 1
        fi
      - |
        echo "Anvil chain #{{.CHAIN_NUMBER}} is up!"

  docker-pull-chains:
    status:
      - '[ "{{.DEPLOY_ENV}}" != "LOCAL" ]'
    internal: true
    cmds:
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-anvil.yml pull

  docker-start-chain-*:
    internal: true
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
    env:
      COMPOSE_ANVIL_FORK_CMD:
        # For right now, the setup is that chain #1 is the Holesky fork, and all others are local Anvil instances.
        # We can add more fork URLs here as needed or move this to a map, json, or other structure in the future.
        sh: |
          case {{.CHAIN_NUMBER}} in
            1) echo "--fork-url {{.ANVIL_HOLESKY_FORK_URL}}" ;;
            *) echo "" ;;
          esac
      COMPOSE_PROJECT_NAME: "anvil-{{.CHAIN_NUMBER}}"
      COMPOSE_ANVIL_PORT:
        sh: task backend:get-anvil-port-{{.CHAIN_NUMBER}}
    cmds:
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-anvil.yml up --force-recreate -d

  # HELPERS
  get-anvil-port-*:
    desc: "Get the Anvil port for a chain number"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
      # We use 1 as the CHAIN_NUMBER, so subtract 1 to keep the base port the same
      ANVIL_PORT: "{{sub (add .ANVIL_BASE_PORT (atoi .CHAIN_NUMBER)) 1}}"
    cmds:
      - echo "{{.ANVIL_PORT}}"

  get-evm-rpc-url-*:
    desc: "Get the RPC URL for a chain number"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
    cmds:
      - |
        case "{{.DEPLOY_ENV}}" in
          "TESTNET")
            task -s backend:get-testnet-evm-rpc-url-{{.CHAIN_NUMBER}}
            ;;
          *)
            task -s backend:get-local-evm-rpc-url-{{.CHAIN_NUMBER}}
            ;;
        esac

  get-testnet-evm-rpc-url-*:
    desc: "Get the testnet RPC URL for a chain number with bounds checking"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
      RPC_URL: "{{index .TESTNET_EVM_RPC_URLS (sub (atoi .CHAIN_NUMBER) 1)}}"
    cmds:
      - |
        if [ -z "{{.RPC_URL}}" ]; then
          echo "Error: TESTNET_EVM_RPC_URLS[{{.CHAIN_NUMBER}}] is empty or not configured" >&2
          exit 1
        fi
        echo "{{.RPC_URL}}"

  get-local-evm-rpc-url-*:
    desc: "Get the local Anvil RPC URL for a chain number"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
      ANVIL_PORT:
        sh: task -s backend:get-anvil-port-{{.CHAIN_NUMBER}}
    cmds:
      - echo "http://localhost:{{.ANVIL_PORT}}"

  get-chain-name-*:
    desc: "Get the chain name for a chain number"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
    cmds:
      - |
        case "{{.DEPLOY_ENV}}" in
          "TESTNET")
            task -s backend:get-testnet-chain-name-{{.CHAIN_NUMBER}}
            ;;
          *)
            task -s backend:get-local-chain-name-{{.CHAIN_NUMBER}}
            ;;
        esac

  get-testnet-chain-name-*:
    desc: "Get the testnet chain name for a chain number with bounds checking"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
      CHAIN_NAME: "{{index .TESTNET_EVM_CHAIN_NAMES (sub (atoi .CHAIN_NUMBER) 1)}}"
    cmds:
      - |
        if [ -z "{{.CHAIN_NAME}}" ]; then
          echo "Error: TESTNET_EVM_CHAIN_NAMES[{{.CHAIN_NUMBER}}] is empty or not configured" >&2
          exit 1
        fi
        echo "{{.CHAIN_NAME}}"

  get-local-chain-name-*:
    desc: "Get the local chain name for a chain number"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
    cmds:
      - |
        echo "evm:{{(add .ANVIL_FORK_CHAIN_ID (sub (atoi .CHAIN_NUMBER) 1))}}"

  get-wavs-endpoint-*:
    desc: "Get the wavs endpoint for an instance"
    vars:
      WAVS_INSTANCE: "{{sub (index .MATCH 0) 1}}"
    cmds:
      - echo "http://localhost:{{add .WAVS_BASE_PORT .WAVS_INSTANCE}}"

  ###################################################################
  ######################## WAVS #####################################
  ###################################################################
  start-wavs:
    desc: "Start WAVS operator instances and aggregator"
    preconditions:
      - test -f "{{.BACKEND_DIR}}/docker-compose-wavs-aggregator.yml"
      - test -f "{{.BACKEND_DIR}}/docker-compose-wavs-instance.yml"
      - sh: "command -v docker"
        msg: "Docker is required but not installed"
    # Pull the latest images before starting
    deps: [docker-pull-wavs]
    cmds:
      - task: start-wavs-inner
        # Optional - pass this in, or 1 by default
        vars:
          OPERATORS: '{{.OPERATORS | default "1"}}'

  docker-pull-wavs:
    internal: true
    cmds:
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-wavs-aggregator.yml pull
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-wavs-instance.yml pull

  start-wavs-inner:
    internal: true
    vars:
      OPERATORS_RANGE:
        sh: seq 1 {{.OPERATORS}}
    requires:
      vars: [OPERATORS]
    deps:
      - task: start-wavs-aggregator
      - for: { var: OPERATORS_RANGE }
        task: start-wavs-{{.ITEM}}

  start-wavs-aggregator:
    internal: true
    deps:
      - task: docker-start-wavs-aggregator
    cmds:
      # Wait for WAVS Aggregator to be up and running
      - |
        for ((i=0; i<{{.HEALTH_CHECK_TIMEOUT}}; i++)); do
          if nc -z 127.0.0.1 {{.WAVS_AGGREGATOR_PORT}}; then
            break
          fi
          echo "Waiting for Aggregator to start on port {{.WAVS_AGGREGATOR_PORT}}..."
          sleep 1
        done
        if ! nc -z 127.0.0.1 {{.WAVS_AGGREGATOR_PORT}}; then
          echo "Aggregator did not start after {{.HEALTH_CHECK_TIMEOUT}} seconds"
          exit 1
        fi
      - echo "Aggregator is up!"

  start-wavs-*:
    internal: true
    vars:
      WAVS_INSTANCE: "{{index .MATCH 0}}"
      WAVS_PORT:
        sh: task backend:get-wavs-port-{{.WAVS_INSTANCE}}
    deps:
      - task: docker-start-wavs-{{.WAVS_INSTANCE}}
    cmds:
      # Wait for WAVS instance to be up and running
      - |
        for ((i=0; i<{{.HEALTH_CHECK_TIMEOUT}}; i++)); do
          if nc -z 127.0.0.1 {{.WAVS_PORT}}; then
            break
          fi
          echo "Waiting for WAVS #{{.WAVS_INSTANCE}} to start on port {{.WAVS_PORT}}..."
          sleep 1
        done
        if ! nc -z 127.0.0.1 {{.WAVS_PORT}}; then
          echo "WAVS #{{.WAVS_INSTANCE}} did not start after {{.HEALTH_CHECK_TIMEOUT}} seconds"
          exit 1
        fi
      - |
        echo "WAVS #{{.WAVS_INSTANCE}} is up!"

  docker-start-wavs-aggregator:
    internal: true
    env:
      COMPOSE_WAVS_AGGREGATOR_PORT: "{{.WAVS_AGGREGATOR_PORT}}"
    cmds:
      - echo "Starting WAVS Aggregator on port {{.WAVS_AGGREGATOR_PORT}}"
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-wavs-aggregator.yml up --force-recreate -d

  docker-start-wavs-*:
    internal: true
    vars:
      WAVS_INSTANCE: "{{index .MATCH 0}}"
    env:
      COMPOSE_PROJECT_NAME: "wavs-operator-{{.WAVS_INSTANCE}}"
      COMPOSE_WAVS_PORT:
        sh: task backend:get-wavs-port-{{.WAVS_INSTANCE}}
      WAVS_SUBMISSION_MNEMONIC:
        sh: task backend:get-wavs-submission-mnemonic-{{.WAVS_INSTANCE}}
    cmds:
      - |
        echo "Starting WAVS #{{.WAVS_INSTANCE}} on port $COMPOSE_WAVS_PORT"
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-wavs-instance.yml up --force-recreate -d

  stop-wavs:
    desc: "Stop all WAVS instances and aggregator"
    cmds:
      - task: stop-wavs-instances
      - task: stop-wavs-aggregator

  stop-wavs-aggregator:
    desc: "Stop WAVS aggregator service"
    cmds:
      - echo "Stopping WAVS Aggregator"
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-wavs-aggregator.yml down --remove-orphans --volumes

  stop-wavs-instances:
    desc: "Stop all WAVS operator instances"
    vars:
      ACTIVE_WAVS:
        sh: seq 1 {{.ACTIVE_WAVS_COUNT}}
    deps:
      - for: { var: ACTIVE_WAVS }
        task: stop-wavs-{{.ITEM}}

  stop-wavs-*:
    internal: true
    vars:
      WAVS_INSTANCE: "{{index .MATCH 0}}"
    cmds:
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --project-name wavs-operator-{{.WAVS_INSTANCE}} --file docker-compose-wavs-instance.yml down --remove-orphans --volumes

  # HELPERS
  get-wavs-port-*:
    desc: "Get the WAVS port for a wavs number"
    vars:
      WAVS_INSTANCE: "{{index .MATCH 0}}"
      # We use 1 as the WAVS_INSTANCE, so subtract 1 to keep the base port the same
      WAVS_PORT: "{{sub (add .WAVS_BASE_PORT (atoi .WAVS_INSTANCE)) 1}}"
    cmds:
      - echo "{{.WAVS_PORT}}"

  get-wavs-submission-mnemonic-*:
    desc: "Get the WAVS submission mnemonic for a wavs instance number"
    vars:
      WAVS_INSTANCE: "{{index .MATCH 0}}"
      ENV_VAR_NAME: "WAVS_SUBMISSION_MNEMONIC_{{.WAVS_INSTANCE}}"
    cmds:
      - echo "${{.ENV_VAR_NAME}}"

  ###################################################################
  ##################### CHAIN CONFIGURATION ##########################
  ###################################################################
  # Only for local evm instances
  # Eventually need to refactor entire codebase to allow for local <=> testnet
  # Since everything is heavily dependent on DEPLOY_ENV atm
  configure-chains:
    status:
      - '[ "{{.DEPLOY_ENV}}" != "LOCAL" ]'
    desc: "Configure chains across all active WAVS operators"
    vars:
      CHAIN_RANGE:
        sh: seq 1 {{.ACTIVE_CHAIN_COUNT}}
    deps:
      - for: { var: CHAIN_RANGE }
        task: configure-evm-chain-{{.ITEM}}

  configure-evm-chain-*:
    desc: "Configure a single chain across all active WAVS operators"
    vars:
      CHAIN_NUMBER: "{{index .MATCH 0}}"
      CHAIN_NAME:
        sh: task backend:get-chain-name-{{.CHAIN_NUMBER}}
      RPC_URL:
        sh: task backend:get-evm-rpc-url-{{.CHAIN_NUMBER}}
      WAVS_RANGE:
        sh: seq 1 {{.ACTIVE_WAVS_COUNT}}
      POLL_INTERVAL_MS: "{{.POLL_INTERVAL_MS | default 7000}}"
    requires:
      vars: [CHAIN_NUMBER]
    deps:
      - for: { var: WAVS_RANGE }
        task: add-evm-chain
        vars:
          CHAIN_NAME: "{{.CHAIN_NAME}}"
          OPERATOR: "{{.ITEM}}"
          HTTP_ENDPOINT: "{{.RPC_URL}}"
          POLL_INTERVAL_MS: "{{.POLL_INTERVAL_MS}}"

  add-evm-chain:
    desc: "Add a new EVM chain to WAVS via POST /chains endpoint"
    requires:
      vars: [NAMESPACE, CHAIN_NAME, OPERATOR]
    vars:
      HTTP_ENDPOINT: "{{.HTTP_ENDPOINT}}"
      NAMESPACE: '{{ index (.CHAIN_NAME | splitList ":") 0 }}'
      CHAIN_ID: '{{ index (.CHAIN_NAME | splitList ":") 1 }}'
      WS_ENDPOINT: "{{.WS_ENDPOINT}}"
      FAUCET_ENDPOINT: "{{.FAUCET_ENDPOINT}}"
      POLL_INTERVAL_MS: "{{.POLL_INTERVAL_MS}}"
      WAVS_ENDPOINT:
        sh: task backend:get-wavs-endpoint-{{.OPERATOR}}
    preconditions:
      - sh: "command -v curl"
        msg: "curl is required but not installed"
    cmds:
      - |
        curl -X POST "{{.WAVS_ENDPOINT}}/chains" \
          -H "Content-Type: application/json" \
          -d '{
            "chain": "{{.NAMESPACE}}:{{.CHAIN_ID}}",
            "config": {
              "type": "evm",
              "chain_id": "{{.CHAIN_ID}}",
              "ws_endpoint": {{.WS_ENDPOINT | quote}},
              "http_endpoint": {{.HTTP_ENDPOINT | quote}},
              "faucet_endpoint": {{.FAUCET_ENDPOINT | quote}},
              "poll_interval_ms": {{.POLL_INTERVAL_MS | atoi | default 7000}}
            }
          }'

  ###################################################################
  ##################### TELEMETRY ###################################
  ###################################################################

  start-telemetry:
    desc: "Start telemetry services (Jaeger and Prometheus)"
    # Pull the latest images before starting
    deps: [docker-pull-telemetry]
    cmds:
      - task: start-telemetry-inner

  docker-pull-telemetry:
    internal: true
    cmds:
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-telemetry.yml pull

  start-telemetry-inner:
    internal: true
    deps: [docker-start-telemetry]
    cmds:
      # Wait for Jaeger and Prometheus to be up and running
      # the deps here will ensure that the docker-start-telemetry task is run first
      - |
        while ! nc -z localhost 16686; do
          echo "Waiting for Jaeger to start on port 16686..."
          sleep 1
        done
      - echo "Jaeger is up and running!"
      - |
        while ! nc -z localhost 9090; do
          echo "Waiting for Prometheus to start on port 9090..."
          sleep 1
        done
      - echo "Prometheus is up and running!"

  docker-start-telemetry:
    internal: true
    cmds:
      - echo "Starting Telemetry"
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-telemetry.yml up --force-recreate -d

  docker-stop-telemetry:
    desc: "Stop telemetry services"
    aliases: [stop-telemetry]
    cmds:
      - echo "Stopping Telemetry"
      - cd "{{.BACKEND_DIR}}" && {{.DOCKER_SUDO}} docker compose --file docker-compose-telemetry.yml down --remove-orphans --volumes
